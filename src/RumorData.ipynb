{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57d8f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Repositories\\\\GitHub\\\\Digital-Twin-Systems-for-Rumor-Analysis\\\\src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af34743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_rumor</th>\n",
       "      <th>user.handle</th>\n",
       "      <th>topic</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBCDanielS</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now 10 dead in a shooting there today RT \"@BBC...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>robbylevy</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@BBCDanielS @BBCWorld I'm guessing this is bei...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ModerateInAll</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BBCDanielS @BBCWorld why would you mention th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GabTarquini</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@BBCDanielS @BBCWorld perps identified?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>freethought41</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_rumor    user.handle  \\\n",
       "0  Charlie Hebdo became well known for publishing...       0.0     BBCDanielS   \n",
       "1  Now 10 dead in a shooting there today RT \"@BBC...       0.0      robbylevy   \n",
       "2  @BBCDanielS @BBCWorld I'm guessing this is bei...       0.0  ModerateInAll   \n",
       "3  @BBCDanielS @BBCWorld why would you mention th...       0.0    GabTarquini   \n",
       "4            @BBCDanielS @BBCWorld perps identified?       0.0  freethought41   \n",
       "\n",
       "          topic  annotation  \n",
       "0  charliehebdo        True  \n",
       "1  charliehebdo        True  \n",
       "2  charliehebdo        True  \n",
       "3  charliehebdo        True  \n",
       "4  charliehebdo        True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "file_path = '../datasets/AnnotatedDataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766f1cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49666 entries, 0 to 49665\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   text         49666 non-null  object \n",
      " 1   is_rumor     49666 non-null  float64\n",
      " 2   user.handle  49666 non-null  object \n",
      " 3   topic        49666 non-null  object \n",
      " 4   annotation   49666 non-null  bool   \n",
      "dtypes: bool(1), float64(1), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied stance mapping to create a new 'stance' column.\n",
      "\n",
      "SUCCESS: All annotation labels were mapped successfully.\n",
      "\n",
      "--- Sample of the processed data ---\n",
      "                                                 text  annotation   stance\n",
      "0   Charlie Hebdo became well known for publishing...        True  support\n",
      "1   Now 10 dead in a shooting there today RT \"@BBC...        True  support\n",
      "2   @BBCDanielS @BBCWorld I'm guessing this is bei...        True  support\n",
      "3   @BBCDanielS @BBCWorld why would you mention th...        True  support\n",
      "4             @BBCDanielS @BBCWorld perps identified?        True  support\n",
      "5         @BBCDanielS @BBCWorld who is charlie hebdo?        True  support\n",
      "6          @im_a_5H_Voter A French satirical magazine        True  support\n",
      "7   @GabTarquini @BBCDanielS @BBCWorld Maybe becau...        True  support\n",
      "8   @S_Jakobsen @BBCDanielS @BBCWorld what's your ...        True  support\n",
      "9   @GabTarquini @BBCDanielS @BBCWorld Several men...        True  support\n",
      "10  @GabTarquini @BBCDanielS @BBCWorld Cossette, a...        True  support\n",
      "11  @S_Jakobsen @BBCDanielS @BBCWorld not quite su...        True  support\n",
      "12  @BBCDanielS @GCGATOR24 I hope they remain open...        True  support\n",
      "13  @GabTarquini @BBCDanielS @BBCWorld Oh come on....        True  support\n",
      "14  @GabTarquini @BBCDanielS @BBCWorld Anyways, I ...        True  support\n",
      "------------------------------------\n",
      "\n",
      "Processed data has been saved to '/Digital-Twin-Systems-for-Rumor-Analysis/datasets/dataset_with_stances.csv'.\n"
     ]
    }
   ],
   "source": [
    "stance_mapping = {\n",
    "    # Support Labels\n",
    "    'true': 'support',\n",
    "    'agreed': 'support',\n",
    "    True: 'support',  # Added boolean True\n",
    "\n",
    "    # Deny Labels\n",
    "    'false': 'deny',\n",
    "    'disagreed': 'deny',\n",
    "    False: 'deny', # Added boolean False\n",
    "\n",
    "    # Query Labels\n",
    "    'appeal-for-more-information': 'query',\n",
    "\n",
    "    # Comment Labels (for general discussion or unverified claims)\n",
    "    'unverified': 'comment',\n",
    "    'comment': 'comment',\n",
    "    'discuss': 'comment'\n",
    "}\n",
    "\n",
    "# --- 3. Apply the Mapping ---\n",
    "# Create a new 'stance' column based on the 'annotation' column.\n",
    "df['stance'] = df['annotation'].map(stance_mapping)\n",
    "print(\"Applied stance mapping to create a new 'stance' column.\")\n",
    "\n",
    "# --- 4. Verification ---\n",
    "# Check if any annotations were not mapped. This is important for data quality.\n",
    "unmapped_count = df['stance'].isnull().sum()\n",
    "if unmapped_count > 0:\n",
    "    print(f\"\\nWARNING: {unmapped_count} annotations could not be mapped.\")\n",
    "    unmapped_values = df[df['stance'].isnull()]['annotation'].unique()\n",
    "    print(\"The following unique values were not found in the mapping dictionary:\")\n",
    "    print(unmapped_values)\n",
    "    print(\"Please add them to the 'stance_mapping' dictionary and rerun the script.\")\n",
    "else:\n",
    "    print(\"\\nSUCCESS: All annotation labels were mapped successfully.\")\n",
    "\n",
    "# Display the first 15 rows to show the original annotation and the new stance\n",
    "print(\"\\n--- Sample of the processed data ---\")\n",
    "print(df[['text', 'annotation', 'stance']].head(15))\n",
    "print(\"------------------------------------\")\n",
    "\n",
    "\n",
    "# --- 5. Save the Processed Data ---\n",
    "# Save the updated DataFrame to a new CSV file for the next steps.\n",
    "output_filename = '../datasets/dataset_with_stances.csv'\n",
    "# df.to_csv(output_filename, index=False)\n",
    "print(f\"\\nProcessed data has been saved to '{output_filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebd5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying sentiment analysis... This may take a moment for a large dataset.\n",
      "Sentiment analysis complete.\n",
      "\n",
      "--- Sample of the processed data with sentiment labels ---\n",
      "                                                 text   stance sentiment\n",
      "0   Charlie Hebdo became well known for publishing...  support  positive\n",
      "1   Now 10 dead in a shooting there today RT \"@BBC...  support  negative\n",
      "2   @BBCDanielS @BBCWorld I'm guessing this is bei...  support  negative\n",
      "3   @BBCDanielS @BBCWorld why would you mention th...  support   neutral\n",
      "4             @BBCDanielS @BBCWorld perps identified?  support   neutral\n",
      "5         @BBCDanielS @BBCWorld who is charlie hebdo?  support   neutral\n",
      "6          @im_a_5H_Voter A French satirical magazine  support   neutral\n",
      "7   @GabTarquini @BBCDanielS @BBCWorld Maybe becau...  support   neutral\n",
      "8   @S_Jakobsen @BBCDanielS @BBCWorld what's your ...  support   neutral\n",
      "9   @GabTarquini @BBCDanielS @BBCWorld Several men...  support   neutral\n",
      "10  @GabTarquini @BBCDanielS @BBCWorld Cossette, a...  support  positive\n",
      "11  @S_Jakobsen @BBCDanielS @BBCWorld not quite su...  support  negative\n",
      "12  @BBCDanielS @GCGATOR24 I hope they remain open...  support  negative\n",
      "13  @GabTarquini @BBCDanielS @BBCWorld Oh come on....  support  positive\n",
      "14  @GabTarquini @BBCDanielS @BBCWorld Anyways, I ...  support  negative\n",
      "----------------------------------------------------------\n",
      "\n",
      "Processed data has been saved to '/Digital-Twin-Systems-for-Rumor-Analysis/datasets/dataset_with_stances.csv'.\n",
      "This file is now ready for the next step: structuring conversations.\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "stance = pd.read_csv('../datasets/dataset_with_stances.csv')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if not isinstance(text, str):\n",
    "        return 'neutral'\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound_score = scores['compound']\n",
    "\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "print(\"Applying sentiment analysis... This may take a moment for a large dataset.\")\n",
    "stance['sentiment'] = stance['text'].fillna('').apply(get_sentiment)\n",
    "print(\"Sentiment analysis complete.\")\n",
    "\n",
    "print(\"\\n--- Sample of the processed data with sentiment labels ---\")\n",
    "print(stance[['text', 'stance', 'sentiment']].head(15))\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "output_filename = '../datasets/dataset_with_stances.csv'\n",
    "# stance.to_csv(output_filename, index=False)\n",
    "print(f\"\\nProcessed data has been saved to '{output_filename}'.\")\n",
    "print(\"This file is now ready for the next step: structuring conversations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9561bc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_rumor</th>\n",
       "      <th>user.handle</th>\n",
       "      <th>topic</th>\n",
       "      <th>annotation</th>\n",
       "      <th>stance</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BBCDanielS</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "      <td>support</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now 10 dead in a shooting there today RT \"@BBC...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>robbylevy</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "      <td>support</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@BBCDanielS @BBCWorld I'm guessing this is bei...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ModerateInAll</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "      <td>support</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BBCDanielS @BBCWorld why would you mention th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GabTarquini</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "      <td>support</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@BBCDanielS @BBCWorld perps identified?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>freethought41</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>True</td>\n",
       "      <td>support</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_rumor    user.handle  \\\n",
       "0  Charlie Hebdo became well known for publishing...       0.0     BBCDanielS   \n",
       "1  Now 10 dead in a shooting there today RT \"@BBC...       0.0      robbylevy   \n",
       "2  @BBCDanielS @BBCWorld I'm guessing this is bei...       0.0  ModerateInAll   \n",
       "3  @BBCDanielS @BBCWorld why would you mention th...       0.0    GabTarquini   \n",
       "4            @BBCDanielS @BBCWorld perps identified?       0.0  freethought41   \n",
       "\n",
       "          topic  annotation   stance sentiment  \n",
       "0  charliehebdo        True  support  positive  \n",
       "1  charliehebdo        True  support  negative  \n",
       "2  charliehebdo        True  support  negative  \n",
       "3  charliehebdo        True  support   neutral  \n",
       "4  charliehebdo        True  support   neutral  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = pd.read_csv('../datasets/dataset_with_stances.csv')\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping posts by topic to form conversation threads...\n",
      "Successfully structured the data into 2 conversations.\n",
      "\n",
      "--- Example: 'charliehebdo' conversation ---\n",
      "Topic: charliehebdo\n",
      "Total Posts: 25491\n",
      "Source Rumor:\n",
      "  Text: Charlie Hebdo became well known for publishing the Muhammed cartoons two years ago\n",
      "  Stance: support\n",
      "  Sentiment: positive\n",
      "First Comment:\n",
      "  Text: Now 10 dead in a shooting there today RT \"@BBCDanielS: Charlie Hebdo became well known for publishing the Muhammed cartoons two years ago”\n",
      "  Stance: support\n",
      "  Sentiment: negative\n",
      "---------------------------------------------\n",
      "\n",
      "Structured conversation data has been saved to '/Digital-Twin-Systems-for-Rumor-Analysis/datasets/structured_conversations.json'.\n",
      "Your data is now ready for the final step: calculating harmfulness scores.\n"
     ]
    }
   ],
   "source": [
    "print(\"Grouping posts by topic to form conversation threads...\")\n",
    "conversations = sentiment.groupby('topic')\n",
    "\n",
    "structured_conversations = {}\n",
    "\n",
    "for topic, group in conversations:\n",
    "    posts = group.to_dict('records')\n",
    "\n",
    "    if posts:\n",
    "        posts[0]['is_source_rumor'] = True\n",
    "        for post in posts[1:]:\n",
    "            post['is_source_rumor'] = False\n",
    "    \n",
    "    structured_conversations[topic] = posts\n",
    "\n",
    "print(f\"Successfully structured the data into {len(structured_conversations)} conversations.\")\n",
    "\n",
    "if 'charliehebdo' in structured_conversations:\n",
    "    print(\"\\n--- Example: 'charliehebdo' conversation ---\")\n",
    "    sample_conversation = structured_conversations['charliehebdo']\n",
    "    print(f\"Topic: charliehebdo\")\n",
    "    print(f\"Total Posts: {len(sample_conversation)}\")\n",
    "    print(\"Source Rumor:\")\n",
    "    print(f\"  Text: {sample_conversation[0]['text']}\")\n",
    "    print(f\"  Stance: {sample_conversation[0]['stance']}\")\n",
    "    print(f\"  Sentiment: {sample_conversation[0]['sentiment']}\")\n",
    "    print(\"First Comment:\")\n",
    "    if len(sample_conversation) > 1:\n",
    "        print(f\"  Text: {sample_conversation[1]['text']}\")\n",
    "        print(f\"  Stance: {sample_conversation[1]['stance']}\")\n",
    "        print(f\"  Sentiment: {sample_conversation[1]['sentiment']}\")\n",
    "    print(\"---------------------------------------------\")\n",
    "\n",
    "import json\n",
    "\n",
    "output_filename = '../datasets/structured_conversations.json'\n",
    "with open(output_filename, 'w') as f:\n",
    "    json.dump(structured_conversations, f, indent=4)\n",
    "\n",
    "print(f\"\\nStructured conversation data has been saved to '{output_filename}'.\")\n",
    "print(\"Your data is now ready for the final step: calculating harmfulness scores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded /Digital-Twin-Systems-for-Rumor-Analysis/datasets/structured_conversations.json\n",
      "\n",
      "Found 2 unique conversation topics.\n",
      "The final output file will have one row for each topic.\n",
      "\n",
      "Calculating harmfulness scores for each conversation...\n",
      "Harmfulness score calculation complete.\n",
      "\n",
      "--- Sample of the final data with harmfulness scores ---\n",
      "          topic                                               text  \\\n",
      "0  charliehebdo  Charlie Hebdo became well known for publishing...   \n",
      "1      ferguson  Black teenage boys are not men. They are child...   \n",
      "\n",
      "   harmfulness_score  harmfulness_score_normalized  \n",
      "0          16.562352                           1.0  \n",
      "1          15.409384                           0.0  \n",
      "---------------------------------------------------------\n",
      "\n",
      "Final dataset for training has been saved to '/Digital-Twin-Systems-for-Rumor-Analysis/datasets/final_rumor_dataset_for_training.csv'.\n",
      "Your data preparation is now complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.stats import skew # Used for the organization score\n",
    "\n",
    "# --- 1. Load the Structured Conversations ---\n",
    "file_path = '../datasets/structured_conversations.json'\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        structured_conversations = json.load(f)\n",
    "    print(f\"Successfully loaded {file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at '{file_path}'.\")\n",
    "    print(\"Please ensure you have run the previous script successfully.\")\n",
    "    exit()\n",
    "\n",
    "# --- VERIFICATION STEP ---\n",
    "# This will print the number of unique topics found in your data.\n",
    "# This number should match the number of rows in your final output file.\n",
    "print(f\"\\nFound {len(structured_conversations)} unique conversation topics.\")\n",
    "print(\"The final output file will have one row for each topic.\")\n",
    "# -------------------------\n",
    "\n",
    "# --- 2. Define Harmfulness Calculation Functions ---\n",
    "\n",
    "def calculate_rumor_sentimentality(comments):\n",
    "    \"\"\"Calculates the intensity of negative emotions (Rc).\"\"\"\n",
    "    negative_comments = sum(1 for comment in comments if comment.get('sentiment') == 'negative')\n",
    "    positive_comments = sum(1 for comment in comments if comment.get('sentiment') == 'positive')\n",
    "    total_sentiment_comments = negative_comments + positive_comments\n",
    "    if total_sentiment_comments == 0:\n",
    "        return 0.0\n",
    "    return negative_comments / total_sentiment_comments\n",
    "\n",
    "def calculate_rumor_approval(comments):\n",
    "    \"\"\"Calculates the level of user support for the rumor (Rr).\"\"\"\n",
    "    support_comments = sum(1 for comment in comments if comment.get('stance') == 'support')\n",
    "    deny_comments = sum(1 for comment in comments if comment.get('stance') == 'deny')\n",
    "    query_comments = sum(1 for comment in comments if comment.get('stance') == 'query')\n",
    "    total_stance_comments = support_comments + deny_comments + query_comments\n",
    "    if total_stance_comments == 0:\n",
    "        return 0.0\n",
    "    # The paper's formula is a bit ambiguous, so we use a common interpretation:\n",
    "    # support vs. total engaged comments.\n",
    "    return support_comments / total_stance_comments\n",
    "\n",
    "def calculate_degree_of_organization(comments, user_handles):\n",
    "    \"\"\"Calculates how widely the rumor has spread (Ro).\"\"\"\n",
    "    if not user_handles:\n",
    "        return 0.0\n",
    "    # The paper suggests calculating skewness of user participation (retweets).\n",
    "    # As a proxy, we'll use the skewness of comment counts per user.\n",
    "    user_comment_counts = pd.Series(user_handles).value_counts()\n",
    "    if len(user_comment_counts) < 3: # Skewness is unreliable for very few data points\n",
    "        return 0.0\n",
    "    return skew(user_comment_counts)\n",
    "\n",
    "# --- 3. Calculate Scores for Each Conversation ---\n",
    "final_rumor_data = []\n",
    "\n",
    "print(\"\\nCalculating harmfulness scores for each conversation...\")\n",
    "for topic, posts in structured_conversations.items():\n",
    "    if not posts:\n",
    "        continue\n",
    "\n",
    "    source_rumor = posts[0]\n",
    "    comments = posts[1:]\n",
    "    \n",
    "    # Extract user handles from comments for organization score\n",
    "    comment_user_handles = [c['user.handle'] for c in comments if 'user.handle' in c]\n",
    "\n",
    "    # Calculate the individual metrics\n",
    "    r_c = calculate_rumor_sentimentality(comments)\n",
    "    r_r = calculate_rumor_approval(comments)\n",
    "    r_o = calculate_degree_of_organization(comments, comment_user_handles)\n",
    "\n",
    "    # The paper mentions Rf, but doesn't define it. We will sum the three defined metrics.\n",
    "    # The final score will be normalized later.\n",
    "    harmfulness_score = r_c + r_r + r_o\n",
    "    \n",
    "    source_rumor['harmfulness_score'] = harmfulness_score\n",
    "    final_rumor_data.append(source_rumor)\n",
    "\n",
    "print(\"Harmfulness score calculation complete.\")\n",
    "\n",
    "# --- 4. Create and Normalize the Final DataFrame ---\n",
    "final_df = pd.DataFrame(final_rumor_data)\n",
    "\n",
    "# Normalize the harmfulness score to be between 0 and 1 for model training.\n",
    "# This makes the training process more stable.\n",
    "min_score = final_df['harmfulness_score'].min()\n",
    "max_score = final_df['harmfulness_score'].max()\n",
    "if max_score > min_score:\n",
    "    final_df['harmfulness_score_normalized'] = (final_df['harmfulness_score'] - min_score) / (max_score - min_score)\n",
    "else:\n",
    "    final_df['harmfulness_score_normalized'] = 0.0\n",
    "\n",
    "\n",
    "# --- 5. Verification ---\n",
    "print(\"\\n--- Sample of the final data with harmfulness scores ---\")\n",
    "print(final_df[['topic', 'text', 'harmfulness_score', 'harmfulness_score_normalized']].head())\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n",
    "# --- 6. Save the Final Dataset ---\n",
    "# This file contains the source rumors and their target harmfulness scores.\n",
    "output_filename = '../datasets/final_rumor_dataset_for_training.csv'\n",
    "final_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nFinal dataset for training has been saved to '{output_filename}'.\")\n",
    "print(\"Your data preparation is now complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rumorenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
